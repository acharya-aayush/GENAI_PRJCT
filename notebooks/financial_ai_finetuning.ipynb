{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c2a212",
   "metadata": {},
   "source": [
    "# Financial AI Fine-tuning with LLaMA 3.2\n",
    "\n",
    "## Project Ideas & Implementation Guide\n",
    "\n",
    "This notebook demonstrates how to fine-tune LLaMA 3.2 for financial applications using QLoRA. We'll explore multiple project ideas and implement a complete financial sentiment analysis system.\n",
    "\n",
    "### Top Financial AI Project Ideas\n",
    "\n",
    "1. **Financial Sentiment Analyzer** - Predict market sentiment from news\n",
    "2. **Personal Finance Assistant** - Answer investment and budgeting questions  \n",
    "3. **Stock Analysis Chatbot** - Explain financial reports and metrics\n",
    "4. **Trading Strategy Explainer** - Teach trading concepts in simple terms\n",
    "5. **Economic Research Assistant** - Summarize complex economic papers\n",
    "\n",
    "Let's start with **Financial Sentiment Analysis** - perfect for beginners!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b9bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "! pip install -q yfinance pandas numpy matplotlib seaborn scikit-learn\n",
    "! pip install -q transformers datasets accelerate peft bitsandbytes\n",
    "! pip install -q huggingface_hub trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Financial Data Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP and ML Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Import our config\n",
    "from config import HUGGINGFACE_TOKEN\n",
    "from huggingface_hub import login\n",
    "\n",
    "print(\"Ready for QLoRA Fine-tuning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf46bc",
   "metadata": {},
   "source": [
    "## Load and Explore Financial Dataset\n",
    "\n",
    "We'll use multiple data sources:\n",
    "- **Yahoo Finance** for stock prices\n",
    "- **Financial news APIs** for sentiment data\n",
    "- **Sample financial data** for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "print(\"Logging into HuggingFace...\")\n",
    "login(token=HUGGINGFACE_TOKEN)\n",
    "\n",
    "# Load sample financial data\n",
    "print(\"Loading Stock Data...\")\n",
    "\n",
    "# Get stock data for major companies\n",
    "tickers = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA']\n",
    "stock_data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(period=\"1mo\")\n",
    "        stock_data[ticker] = hist\n",
    "        print(f\"Loaded {ticker}: {len(hist)} days of data\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {ticker}: {e}\")\n",
    "\n",
    "print(f\"Successfully loaded data for {len(stock_data)} stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b543bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic financial sentiment dataset\n",
    "print(\"Creating Financial Sentiment Dataset...\")\n",
    "\n",
    "# Sample financial news with sentiment labels\n",
    "financial_data = [\n",
    "    {\n",
    "        \"text\": \"Apple reports record quarterly revenue of $123 billion, beating analyst expectations\",\n",
    "        \"sentiment\": \"BULLISH\",\n",
    "        \"explanation\": \"Strong earnings beat indicates positive company performance\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Tesla faces production challenges as supply chain issues continue to impact deliveries\", \n",
    "        \"sentiment\": \"BEARISH\",\n",
    "        \"explanation\": \"Production problems suggest potential revenue decline\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Microsoft announces new AI partnership, stock price jumps 5% in after-hours trading\",\n",
    "        \"sentiment\": \"BULLISH\", \n",
    "        \"explanation\": \"AI partnerships indicate future growth potential\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Amazon warehouse workers vote to unionize, raising concerns about operational costs\",\n",
    "        \"sentiment\": \"BEARISH\",\n",
    "        \"explanation\": \"Unionization could increase labor costs and reduce profitability\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Federal Reserve hints at potential interest rate cuts, market rallies broadly\",\n",
    "        \"sentiment\": \"BULLISH\",\n",
    "        \"explanation\": \"Lower interest rates typically boost stock valuations\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Inflation data comes in higher than expected, sparking concerns about economic slowdown\",\n",
    "        \"sentiment\": \"BEARISH\", \n",
    "        \"explanation\": \"High inflation may lead to tighter monetary policy\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to instruction format for fine-tuning\n",
    "training_data = []\n",
    "\n",
    "for item in financial_data:\n",
    "    instruction = f\"Analyze the following financial news and provide sentiment (BULLISH/BEARISH/MIXED) with explanation:\\n\\n{item['text']}\"\n",
    "    response = f\"Sentiment: {item['sentiment']}\\nExplanation: {item['explanation']}\"\n",
    "    \n",
    "    training_data.append({\n",
    "        \"instruction\": instruction,\n",
    "        \"response\": response,\n",
    "        \"text\": f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{response}<|eot_id|>\"\n",
    "    })\n",
    "\n",
    "print(f\"Created {len(training_data)} training examples\")\n",
    "print(\"\\nSample Training Example:\")\n",
    "print(\"Instruction:\", training_data[0][\"instruction\"][:100] + \"...\")\n",
    "print(\"Response:\", training_data[0][\"response\"][:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3379e3d8",
   "metadata": {},
   "source": [
    "## Setup Model for Fine-tuning\n",
    "\n",
    "Load LLaMA 3.2 with 4-bit quantization and prepare for QLoRA training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16547a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Loading {model_name}...\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Configure 4-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ") if torch.cuda.is_available() else None\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Load model\n",
    "if torch.cuda.is_available() and bnb_config:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(\"cuda\")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure QLoRA\n",
    "print(\"Setting up QLoRA configuration...\")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                               # Rank of the low-rank matrices\n",
    "    lora_alpha=32,                      # Scaling parameter\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention layers\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"       # MLP layers\n",
    "    ],\n",
    "    lora_dropout=0.1,                   # Dropout for LoRA layers\n",
    "    bias=\"none\",                        # No bias terms\n",
    "    task_type=TaskType.CAUSAL_LM        # Causal language modeling\n",
    ")\n",
    "\n",
    "print(\"LoRA Configuration:\")\n",
    "print(f\"  - Rank (r): {lora_config.r}\")\n",
    "print(f\"  - Alpha: {lora_config.lora_alpha}\")\n",
    "print(f\"  - Target modules: {lora_config.target_modules}\")\n",
    "print(f\"  - Dropout: {lora_config.lora_dropout}\")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "print(\"\\nApplying LoRA adapters...\")\n",
    "model.gradient_checkpointing_enable()\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Memory after LoRA: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf210786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset for training\n",
    "print(\"Preparing training dataset...\")\n",
    "\n",
    "# Convert to HuggingFace dataset\n",
    "dataset = Dataset.from_list(training_data)\n",
    "\n",
    "# Configure training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./financial-llama-lora\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    warmup_steps=10,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    optim=\"adamw_torch\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None  # Disable wandb/tensorboard\n",
    ")\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  - Output directory: {training_args.output_dir}\")\n",
    "print(f\"  - Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  - Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  - Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  - Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  - FP16: {training_args.fp16}\")\n",
    "\n",
    "# Initialize trainer\n",
    "print(\"\\nInitializing SFT Trainer...\")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    packing=False\n",
    ")\n",
    "\n",
    "print(\"Starting fine-tuning...\")\n",
    "print(\"This will take several minutes depending on your GPU...\")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(\"Model saved to: ./financial-llama-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model\n",
    "print(\"Testing Fine-tuned Model...\")\n",
    "\n",
    "def test_financial_sentiment(text):\n",
    "    instruction = f\"Analyze the following financial news and provide sentiment (BULLISH/BEARISH/MIXED) with explanation:\\n\\n{text}\"\n",
    "    formatted_prompt = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n{instruction}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "    \n",
    "    inputs = tokenizer.encode(formatted_prompt, return_tensors=\"pt\")\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=inputs.shape[1] + 150,\n",
    "            num_return_sequences=1,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response.split(\"assistant<|end_header_id|>\")[-1].strip()\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    \"Apple announces record iPhone sales for Q4 2024\",\n",
    "    \"Major bank reports significant losses due to loan defaults\", \n",
    "    \"New cryptocurrency regulations create market uncertainty\",\n",
    "    \"Tech sector shows strong growth in AI investments\"\n",
    "]\n",
    "\n",
    "print(f\"Running {len(test_cases)} test cases...\\n\")\n",
    "\n",
    "for i, test_case in enumerate(test_cases):\n",
    "    print(f\"Test Case {i+1}:\")\n",
    "    print(f\"News: {test_case}\")\n",
    "    result = test_financial_sentiment(test_case)\n",
    "    print(f\"Analysis: {result}\\n\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ce526",
   "metadata": {},
   "source": [
    "## Next Steps & Applications\n",
    "\n",
    "### Deployment Options\n",
    "1. **Local Inference** - Use the fine-tuned model locally for analysis\n",
    "2. **API Service** - Deploy as a REST API using FastAPI or Flask\n",
    "3. **Streamlit App** - Create an interactive web interface\n",
    "4. **Integration** - Embed in trading platforms or financial apps\n",
    "\n",
    "### Expanding the Project\n",
    "1. **More Data** - Add real financial news datasets\n",
    "2. **Multi-class Sentiment** - Include confidence scores and sector-specific analysis\n",
    "3. **Real-time Processing** - Connect to live news feeds\n",
    "4. **Backtesting** - Test trading strategies based on sentiment signals\n",
    "\n",
    "### Other Financial AI Projects\n",
    "1. **Portfolio Advisor** - Personalized investment recommendations\n",
    "2. **Risk Assessment** - Analyze investment risk profiles\n",
    "3. **Market Prediction** - Price movement forecasting\n",
    "4. **Earnings Call Analysis** - Summarize quarterly earnings calls\n",
    "5. **Regulatory Compliance** - Analyze regulatory filings and impacts\n",
    "\n",
    "The financial AI space offers endless possibilities for innovation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78233852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Financial Data from Multiple Sources\n",
    "\n",
    "# 1. Stock Price Data\n",
    "def get_stock_data(symbol, period=\"1y\"):\n",
    "    \"\"\"Download stock data from Yahoo Finance\"\"\"\n",
    "    stock = yf.Ticker(symbol)\n",
    "    data = stock.history(period=period)\n",
    "    return data\n",
    "\n",
    "# 2. Sample Financial News Data (we'll create synthetic data for demo)\n",
    "def create_sample_financial_data():\n",
    "    \"\"\"Create sample financial news with sentiment labels\"\"\"\n",
    "    sample_data = [\n",
    "        {\n",
    "            \"news\": \"Apple reports record Q4 earnings, beating expectations by 15%\",\n",
    "            \"sentiment\": \"BULLISH\",\n",
    "            \"confidence\": \"HIGH\",\n",
    "            \"market_impact\": \"Stock likely to rise 35% in next session\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"Tesla faces production delays due to supply chain issues\",\n",
    "            \"sentiment\": \"BEARISH\", \n",
    "            \"confidence\": \"MEDIUM\",\n",
    "            \"market_impact\": \"Stock may decline 23% short term\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"Federal Reserve maintains interest rates, signals stable policy\",\n",
    "            \"sentiment\": \"NEUTRAL\",\n",
    "            \"confidence\": \"HIGH\", \n",
    "            \"market_impact\": \"Market likely to remain stable\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"Microsoft announces massive AI investment, partners with OpenAI\",\n",
    "            \"sentiment\": \"BULLISH\",\n",
    "            \"confidence\": \"HIGH\",\n",
    "            \"market_impact\": \"Stock expected to gain 46% on AI optimism\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"Banking sector faces regulatory pressure over lending practices\",\n",
    "            \"sentiment\": \"BEARISH\",\n",
    "            \"confidence\": \"MEDIUM\",\n",
    "            \"market_impact\": \"Bank stocks may underperform by 12%\"\n",
    "        }\n",
    "    ]\n",
    "    return pd.DataFrame(sample_data)\n",
    "\n",
    "# Load sample data\n",
    "print(\"Loading Stock Data...\")\n",
    "stocks = ['AAPL', 'TSLA', 'MSFT', 'GOOGL']\n",
    "stock_data = {}\n",
    "\n",
    "for symbol in stocks:\n",
    "    try:\n",
    "        stock_data[symbol] = get_stock_data(symbol, \"3mo\")\n",
    "        print(f\"{symbol}: {len(stock_data[symbol])} days of data\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {symbol}: {e}\")\n",
    "\n",
    "# Load financial news data\n",
    "print(\"\\nLoading Financial News Data...\")\n",
    "news_df = create_sample_financial_data()\n",
    "print(f\"Loaded {len(news_df)} news samples\")\n",
    "print(\"\\nSample news data:\")\n",
    "print(news_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd80328a",
   "metadata": {},
   "source": [
    "## Financial Data Preprocessing\n",
    "\n",
    "Prepare data for LLaMA finetuning by creating instructionfollowing format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Data Preprocessing for LLaMA Finetuning\n",
    "\n",
    "def create_instruction_format(row):\n",
    "    \"\"\"Convert financial news to instructionfollowing format\"\"\"\n",
    "    instruction = \"Analyze the sentiment of this financial news and predict market impact:\"\n",
    "    input_text = row['news']\n",
    "    \n",
    "    # Create detailed output\n",
    "    output = f\"\"\"SENTIMENT: {row['sentiment']}\n",
    "CONFIDENCE: {row['confidence']}\n",
    "ANALYSIS: {row['market_impact']}\n",
    "\n",
    "REASONING: \"\"\"\n",
    "    \n",
    "    if row['sentiment'] == 'BULLISH':\n",
    "        output += \"This news contains positive indicators that typically drive investor confidence and buying activity.\"\n",
    "    elif row['sentiment'] == 'BEARISH':\n",
    "        output += \"This news contains negative factors that may cause investor concern and selling pressure.\"\n",
    "    else:\n",
    "        output += \"This news presents neutral information with limited immediate market impact.\"\n",
    "    \n",
    "    return {\n",
    "        'instruction': instruction,\n",
    "        'input': input_text,\n",
    "        'output': output\n",
    "    }\n",
    "\n",
    "# Convert to instruction format\n",
    "print(\"Converting to Instruction Format...\")\n",
    "instruction_data = []\n",
    "\n",
    "for _, row in news_df.iterrows():\n",
    "    formatted = create_instruction_format(row)\n",
    "    instruction_data.append(formatted)\n",
    "\n",
    "# Create training dataset\n",
    "train_df = pd.DataFrame(instruction_data)\n",
    "print(f\"Created {len(train_df)} training examples\")\n",
    "\n",
    "# Show example\n",
    "print(\"\\nExample Training Format:\")\n",
    "print(\"INSTRUCTION:\", train_df.iloc[0]['instruction'])\n",
    "print(\"INPUT:\", train_df.iloc[0]['input'])\n",
    "print(\"OUTPUT:\", train_df.iloc[0]['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7cdb2",
   "metadata": {},
   "source": [
    "## Feature Engineering for Financial Data\n",
    "\n",
    "Create additional financial features and expand our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dee95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering  Create More Financial Training Examples\n",
    "\n",
    "def generate_financial_examples():\n",
    "    \"\"\"Generate more diverse financial training examples\"\"\"\n",
    "    \n",
    "    # Financial scenarios with different complexities\n",
    "    scenarios = [\n",
    "        # Earnings scenarios\n",
    "        {\n",
    "            \"news\": \"Company beats earnings by 20% but revenues miss expectations\",\n",
    "            \"sentiment\": \"NEUTRAL\",\n",
    "            \"reasoning\": \"Mixed signals  strong profitability but concerning revenue growth\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"Dividend increase announced alongside share buyback program\", \n",
    "            \"sentiment\": \"BULLISH\",\n",
    "            \"reasoning\": \"Strong cash position and commitment to shareholder returns\"\n",
    "        },\n",
    "        # Market scenarios  \n",
    "        {\n",
    "            \"news\": \"Inflation data comes in higher than expected at 6.2%\",\n",
    "            \"sentiment\": \"BEARISH\", \n",
    "            \"reasoning\": \"High inflation may lead to more aggressive Fed policy\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"GDP growth accelerates to 3.5% in latest quarter\",\n",
    "            \"sentiment\": \"BULLISH\",\n",
    "            \"reasoning\": \"Strong economic growth supports corporate earnings\"\n",
    "        },\n",
    "        # Sectorspecific scenarios\n",
    "        {\n",
    "            \"news\": \"New breakthrough in quantum computing announced by tech giant\",\n",
    "            \"sentiment\": \"BULLISH\",\n",
    "            \"reasoning\": \"Technological advancement creates competitive advantage\"\n",
    "        },\n",
    "        {\n",
    "            \"news\": \"Energy sector faces headwinds from renewable energy transition\",\n",
    "            \"sentiment\": \"BEARISH\",\n",
    "            \"reasoning\": \"Longterm structural challenges for traditional energy\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    expanded_data = []\n",
    "    for scenario in scenarios:\n",
    "        formatted = {\n",
    "            'instruction': \"Analyze the sentiment of this financial news and predict market impact:\",\n",
    "            'input': scenario['news'],\n",
    "            'output': f\"SENTIMENT: {scenario['sentiment']}\\nREASONING: {scenario['reasoning']}\"\n",
    "        }\n",
    "        expanded_data.append(formatted)\n",
    "    \n",
    "    return expanded_data\n",
    "\n",
    "# Add more training examples\n",
    "print(\"Generating Additional Training Examples...\")\n",
    "additional_examples = generate_financial_examples()\n",
    "expanded_df = pd.concat([train_df, pd.DataFrame(additional_examples)], ignore_index=True)\n",
    "\n",
    "print(f\"Expanded dataset to {len(expanded_df)} examples\")\n",
    "print(f\"Sentiment distribution:\")\n",
    "print(expanded_df['output'].str.contains('BULLISH').sum(), \"Bullish examples\")\n",
    "print(expanded_df['output'].str.contains('BEARISH').sum(), \"Bearish examples\") \n",
    "print(expanded_df['output'].str.contains('NEUTRAL').sum(), \"Neutral examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15b2a4a",
   "metadata": {},
   "source": [
    "## Model Selection and Architecture\n",
    "\n",
    "Now let's set up our LLaMA 3.2 model with QLoRA for financial finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911bf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection  Load LLaMA 3.2 with QLoRA Setup\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Login to HuggingFace\n",
    "print(\"Logging into HuggingFace...\")\n",
    "login(token=HUGGINGFACE_TOKEN)\n",
    "\n",
    "# Configure 4bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "print(\"Loading LLaMA 3.2 Model...\")\n",
    "model_id = \"metallama/Llama3.23BInstruct\"\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    print(\"Model loaded successfully!\")\n",
    "    print(f\"GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Make sure you have access to LLaMA 3.2 model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1c857",
   "metadata": {},
   "source": [
    "## Finetuning Hyperparameters\n",
    "\n",
    "Configure QLoRA parameters specifically optimized for financial text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA Configuration for Financial Finetuning\n",
    "\n",
    "# LoRA configuration optimized for financial text\n",
    "lora_config = LoraConfig(\n",
    "    r=16,                               # Rank  balance between efficiency and performance\n",
    "    lora_alpha=32,                      # Scaling parameter\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # Attention layers\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"       # MLP layers  \n",
    "    ],\n",
    "    lora_dropout=0.1,                   # Prevent overfitting\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "print(f\"LoRA Parameters:\")\n",
    "print(f\"    Rank (r): {lora_config.r}\")\n",
    "print(f\"    Alpha: {lora_config.lora_alpha}\")\n",
    "print(f\"    Dropout: {lora_config.lora_dropout}\")\n",
    "print(f\"    Target modules: {len(lora_config.target_modules)} layers\")\n",
    "\n",
    "# Apply LoRA to model\n",
    "try:\n",
    "    model.gradient_checkpointing_enable()\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    # Calculate trainable parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(\"\\nQLoRA Applied Successfully!\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"GPU Memory after LoRA: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error applying LoRA: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b437e",
   "metadata": {},
   "source": [
    "## Model Training and Validation\n",
    "\n",
    "Set up the training pipeline with proper data formatting and training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefde028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Training Data and Setup Training Pipeline\n",
    "\n",
    "def format_instruction(example):\n",
    "    \"\"\"Format examples for instruction tuning\"\"\"\n",
    "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{example['instruction']}\n",
    "\n",
    "{example['input']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{example['output']}<|eot_id|>\"\"\"\n",
    "    return prompt\n",
    "\n",
    "# Convert DataFrame to Hugging Face Dataset\n",
    "print(\"Preparing Training Dataset...\")\n",
    "\n",
    "# Format all examples\n",
    "formatted_examples = []\n",
    "for _, row in expanded_df.iterrows():\n",
    "    formatted_text = format_instruction(row)\n",
    "    formatted_examples.append({\"text\": formatted_text})\n",
    "\n",
    "# Create Dataset\n",
    "train_dataset = Dataset.from_list(formatted_examples)\n",
    "\n",
    "# Tokenize dataset\n",
    "def tokenize_function(examples):\n",
    "    tokens = tokenizer(examples[\"text\"], truncation=True, padding=True, max_length=512)\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
    "    return tokens\n",
    "\n",
    "print(\"Tokenizing Dataset...\")\n",
    "tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(f\"Dataset prepared: {len(tokenized_dataset)} examples\")\n",
    "print(f\"Max sequence length: 512 tokens\")\n",
    "\n",
    "# Show tokenized example\n",
    "print(\"\\nSample Tokenized Input (first 100 chars):\")\n",
    "sample_text = train_dataset[0][\"text\"]\n",
    "print(sample_text[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54e9d8",
   "metadata": {},
   "source": [
    "## Financial Performance Metrics\n",
    "\n",
    "Define evaluation metrics specific to financial AI applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421efb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Performance Evaluation Functions\n",
    "\n",
    "def evaluate_financial_predictions(predictions, actual_sentiments):\n",
    "    \"\"\"Evaluate financial sentiment predictions\"\"\"\n",
    "    \n",
    "    # Extract sentiments from predictions\n",
    "    pred_sentiments = []\n",
    "    for pred in predictions:\n",
    "        if \"BULLISH\" in pred.upper():\n",
    "            pred_sentiments.append(\"BULLISH\")\n",
    "        elif \"BEARISH\" in pred.upper():\n",
    "            pred_sentiments.append(\"BEARISH\") \n",
    "        else:\n",
    "            pred_sentiments.append(\"NEUTRAL\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(actual_sentiments, pred_sentiments)\n",
    "    report = classification_report(actual_sentiments, pred_sentiments)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"classification_report\": report,\n",
    "        \"predictions\": pred_sentiments\n",
    "    }\n",
    "\n",
    "def test_financial_model(model, tokenizer, test_cases):\n",
    "    \"\"\"Test model on financial scenarios\"\"\"\n",
    "    \n",
    "    print(\"testing Financial AI Model...\")\n",
    "    results = []\n",
    "    \n",
    "    for i, case in enumerate(test_cases):\n",
    "        # Format prompt\n",
    "        prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Analyze the sentiment of this financial news and predict market impact:\n",
    "\n",
    "{case['news']}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Generate prediction\n",
    "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs,\n",
    "                max_length=inputs.shape[1] + 150,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # Decode response\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        generated_text = response[len(prompt):].strip()\n",
    "        \n",
    "        results.append({\n",
    "            \"news\": case['news'],\n",
    "            \"expected\": case.get('expected_sentiment', 'Unknown'),\n",
    "            \"prediction\": generated_text,\n",
    "            \"case_number\": i + 1\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nTest Case {i+1}:\")\n",
    "        print(f\"News: {case['news']}\")\n",
    "        print(f\"Prediction: {generated_text[:100]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"news\": \"Amazon reports 25% growth in cloud services revenue\",\n",
    "        \"expected_sentiment\": \"BULLISH\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"Major tech company announces 10,000 layoffs amid economic uncertainty\", \n",
    "        \"expected_sentiment\": \"BEARISH\"\n",
    "    },\n",
    "    {\n",
    "        \"news\": \"Federal Reserve pauses rate hikes, maintains current policy\",\n",
    "        \"expected_sentiment\": \"NEUTRAL\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"Financial evaluation framework ready!\")\n",
    "print(f\"{len(test_cases)} test cases prepared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705961e",
   "metadata": {},
   "source": [
    "## Backtesting Strategy\n",
    "\n",
    "Implement a framework to test how our AI predictions would perform in real trading scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Financial Backtesting Framework\n",
    "\n",
    "class SimpleFinancialBacktester:\n",
    "    def __init__(self, initial_capital=10000):\n",
    "        self.initial_capital = initial_capital\n",
    "        self.capital = initial_capital\n",
    "        self.positions = {}\n",
    "        self.trade_history = []\n",
    "        \n",
    "    def execute_trade(self, symbol, sentiment, confidence, current_price):\n",
    "        \"\"\"Execute trade based on AI sentiment prediction\"\"\"\n",
    "        \n",
    "        # Trading logic based on sentiment\n",
    "        if sentiment == \"BULLISH\" and confidence == \"HIGH\":\n",
    "            # Buy signal  allocate 10% of capital\n",
    "            position_size = self.capital * 0.1\n",
    "            shares = position_size / current_price\n",
    "            \n",
    "            self.positions[symbol] = {\n",
    "                \"shares\": shares,\n",
    "                \"entry_price\": current_price,\n",
    "                \"entry_date\": datetime.now(),\n",
    "                \"sentiment\": sentiment\n",
    "            }\n",
    "            \n",
    "            self.capital = position_size\n",
    "            self.trade_history.append({\n",
    "                \"action\": \"BUY\",\n",
    "                \"symbol\": symbol,\n",
    "                \"shares\": shares,\n",
    "                \"price\": current_price,\n",
    "                \"sentiment\": sentiment,\n",
    "                \"capital_remaining\": self.capital\n",
    "            })\n",
    "            \n",
    "        elif sentiment == \"BEARISH\" and symbol in self.positions:\n",
    "            # Sell signal  close position\n",
    "            position = self.positions[symbol]\n",
    "            proceeds = position[\"shares\"] * current_price\n",
    "            \n",
    "            profit_loss = proceeds  (position[\"shares\"] * position[\"entry_price\"])\n",
    "            self.capital += proceeds\n",
    "            \n",
    "            self.trade_history.append({\n",
    "                \"action\": \"SELL\", \n",
    "                \"symbol\": symbol,\n",
    "                \"shares\": position[\"shares\"],\n",
    "                \"price\": current_price,\n",
    "                \"profit_loss\": profit_loss,\n",
    "                \"capital_remaining\": self.capital\n",
    "            })\n",
    "            \n",
    "            del self.positions[symbol]\n",
    "    \n",
    "    def calculate_performance(self):\n",
    "        \"\"\"Calculate portfolio performance metrics\"\"\"\n",
    "        \n",
    "        # Calculate total return\n",
    "        current_value = self.capital\n",
    "        for symbol, position in self.positions.items():\n",
    "            # For demo, assume current price = entry price (no real price data)\n",
    "            current_value += position[\"shares\"] * position[\"entry_price\"]\n",
    "\n",
    "        total_return = ( current_value - self.initial_capital ) / self.initial_capital\n",
    "\n",
    "        # Calculate win rate\n",
    "        profitable_trades = [t for t in self.trade_history if t.get(\"profit_loss\", 0) > 0]\n",
    "        total_trades = len([t for t in self.trade_history if \"profit_loss\" in t])\n",
    "        win_rate = len(profitable_trades) / total_trades if total_trades > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"total_return\": total_return * 100,  # Convert to percentage\n",
    "            \"final_capital\": current_value,\n",
    "            \"win_rate\": win_rate * 100,\n",
    "            \"total_trades\": total_trades,\n",
    "            \"profitable_trades\": len(profitable_trades)\n",
    "        }\n",
    "\n",
    "# Demo backtesting\n",
    "print(\"Financial Backtesting Demo\")\n",
    "backtester = SimpleFinancialBacktester(initial_capital=10000)\n",
    "\n",
    "# Simulate some trades based on our AI predictions\n",
    "demo_predictions = [\n",
    "    {\"symbol\": \"AAPL\", \"sentiment\": \"BULLISH\", \"confidence\": \"HIGH\", \"price\": 150.0},\n",
    "    {\"symbol\": \"TSLA\", \"sentiment\": \"BEARISH\", \"confidence\": \"MEDIUM\", \"price\": 200.0}, \n",
    "    {\"symbol\": \"MSFT\", \"sentiment\": \"BULLISH\", \"confidence\": \"HIGH\", \"price\": 300.0},\n",
    "]\n",
    "\n",
    "print(\"\\nExecuting AIBased Trades...\")\n",
    "for pred in demo_predictions:\n",
    "    backtester.execute_trade(pred[\"symbol\"], pred[\"sentiment\"], pred[\"confidence\"], pred[\"price\"])\n",
    "\n",
    "# Show performance\n",
    "performance = backtester.calculate_performance()\n",
    "print(f\"\\nBacktesting Results:\")\n",
    "print(f\"Final Capital: ${performance['final_capital']:,.2f}\")\n",
    "print(f\"Total Return: {performance['total_return']:.2f}%\")\n",
    "print(f\"Win Rate: {performance['win_rate']:.1f}%\")\n",
    "print(f\"Total Trades: {performance['total_trades']}\")\n",
    "\n",
    "print(\"\\nBacktesting framework ready for real testing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb00c26",
   "metadata": {},
   "source": [
    "## Risk Analysis and Visualization\n",
    "\n",
    "Create comprehensive visualizations for portfolio performance and risk analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk Analysis and Visualization\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_financial_dashboard(stock_data, predictions_data):\n",
    "    \"\"\"Create comprehensive financial AI dashboard\"\"\"\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('Stock Price Trends', 'Sentiment Distribution', \n",
    "                       'Prediction Confidence', 'Portfolio Performance'),\n",
    "        specs=[[{\"secondary_y\": True}, {\"type\": \"pie\"}],\n",
    "               [{\"type\": \"bar\"}, {\"secondary_y\": True}]]\n",
    "    )\n",
    "    \n",
    "    # 1. Stock Price Trends\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    for i, (symbol, data) in enumerate(stock_data.items()):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=data.index, \n",
    "                y=data['Close'],\n",
    "                name=f'{symbol} Price',\n",
    "                line=dict(color=colors[i % len(colors)])\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "    \n",
    "    # 2. Sentiment Distribution\n",
    "    sentiment_counts = {\n",
    "        'Bullish': 3,\n",
    "        'Bearish': 2, \n",
    "        'Neutral': 1\n",
    "    }\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=list(sentiment_counts.keys()),\n",
    "            values=list(sentiment_counts.values()),\n",
    "            name=\"Sentiment\",\n",
    "            marker_colors=['#2ca02c', '#d62728', '#ff7f0e']\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # 3. Prediction Confidence\n",
    "    confidence_data = ['HIGH', 'MEDIUM', 'HIGH', 'MEDIUM', 'HIGH']\n",
    "    confidence_counts = {conf: confidence_data.count(conf) for conf in set(confidence_data)}\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=list(confidence_counts.keys()),\n",
    "            y=list(confidence_counts.values()),\n",
    "            name=\"Confidence\",\n",
    "            marker_color=['#2ca02c', '#ff7f0e']\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # 4. Portfolio Performance Simulation\n",
    "    dates = pd.date_range(start='20240101', periods=30, freq='D')\n",
    "    portfolio_values = np.cumsum(np.random.normal(0.002, 0.02, 30)) + 1\n",
    "    portfolio_values = 10000 * portfolio_values\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=dates,\n",
    "            y=portfolio_values,\n",
    "            name='Portfolio Value',\n",
    "            line=dict(color='#1f77b4', width=3)\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=\"Financial AI Analytics Dashboard\",\n",
    "        height=800,\n",
    "        showlegend=True,\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Risk Metrics Calculation\n",
    "def calculate_risk_metrics(returns):\n",
    "    \"\"\"Calculate comprehensive risk metrics\"\"\"\n",
    "    \n",
    "    returns_array = np.array(returns)\n",
    "    \n",
    "    # Basic risk metrics\n",
    "    volatility = np.std(returns_array) * np.sqrt(252)  # Annualized\n",
    "    sharpe_ratio = np.mean(returns_array) / np.std(returns_array) * np.sqrt(252)\n",
    "    max_drawdown = np.min(np.cumsum(returns_array))\n",
    "    \n",
    "    # Value at Risk (95% confidence)\n",
    "    var_95 = np.percentile(returns_array, 5)\n",
    "    \n",
    "    return {\n",
    "        \"volatility\": volatility * 100,\n",
    "        \"sharpe_ratio\": sharpe_ratio,\n",
    "        \"max_drawdown\": max_drawdown * 100,\n",
    "        \"var_95\": var_95 * 100\n",
    "    }\n",
    "\n",
    "# Generate sample returns for risk analysis\n",
    "print(\"Creating Financial Dashboard...\")\n",
    "sample_returns = np.random.normal(0.001, 0.02, 100)  # Daily returns\n",
    "risk_metrics = calculate_risk_metrics(sample_returns)\n",
    "\n",
    "print(\"Risk Analysis Results:\")\n",
    "print(f\"Annualized Volatility: {risk_metrics['volatility']:.2f}%\")\n",
    "print(f\"Sharpe Ratio: {risk_metrics['sharpe_ratio']:.2f}\")\n",
    "print(f\"Maximum Drawdown: {risk_metrics['max_drawdown']:.2f}%\")\n",
    "print(f\"Value at Risk (95%): {risk_metrics['var_95']:.2f}%\")\n",
    "\n",
    "# Create dashboard\n",
    "if 'stock_data' in locals() and stock_data:\n",
    "    dashboard = create_financial_dashboard(stock_data, expanded_df)\n",
    "    print(\"\\nFinancial Dashboard Created!\")\n",
    "    print(\"Dashboard includes:\")\n",
    "    print(\"    Stock price trends\")\n",
    "    print(\"    Sentiment distribution\") \n",
    "    print(\"    Prediction confidence levels\")\n",
    "    print(\"    Portfolio performance simulation\")\n",
    "    \n",
    "    # Show dashboard (in real Jupyter notebook)\n",
    "    # dashboard.show()\n",
    "else:\n",
    "    print(\"Dashboard ready  run stock data loading first!\")\n",
    "\n",
    "print(\"\\nFinancial AI Finetuning Pipeline Complete!\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. finetune the model with your training data\")\n",
    "print(\"2. Test on real financial news\")\n",
    "print(\"3. Implement live trading strategy\")\n",
    "print(\"4. Monitor performance and iterate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e5755",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Project Implementation Guide\n",
    "\n",
    "### Quick Start Options:\n",
    "\n",
    "1. **Beginner**: Start with sentiment analysis on financial news\n",
    "2. **Intermediate**: Add stock price correlation analysis  \n",
    "3. **Advanced**: Build a full trading strategy with risk management\n",
    "\n",
    "### Data Sources to Explore:\n",
    "\n",
    " **Financial News**: Alpha Vantage, Polygon.io, NewsAPI\n",
    " **Social Sentiment**: Reddit API, Twitter API\n",
    " **Market Data**: Yahoo Finance, IEX Cloud\n",
    " **Economic Data**: FRED, World Bank APIs\n",
    "\n",
    "### Model Improvements:\n",
    "\n",
    " **Finetune on domainspecific data**: Financial reports, earnings calls\n",
    " **Add market context**: Include broader market conditions\n",
    " **Multimodal inputs**: Combine text with price charts\n",
    " **Realtime inference**: Deploy for live market analysis\n",
    "\n",
    "### Ready to start your financial AI journey! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
